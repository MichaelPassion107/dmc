{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 6.3 - Improving the model\n",
    "\n",
    "In this section of the lab, you will be asked to apply what you have learned to create a RNN model that can generate new sequences of text based on what it has learned from a large set of existing text. In this case we will be using the full text of Lewis Carroll's *Alice in Wonderland*. Your task for the assignment is to:\n",
    "\n",
    "- format the book text into a set of training data\n",
    "- define a RNN model in Keras based on one or more LSTM or GRU layers\n",
    "- train the model with the training data\n",
    "- use the trained model to generate new text\n",
    "\n",
    "Our previous model based on Obama's essay was prone to overfitting since there was not that much data to learn from. Thus, the generated text was either unintelligeable (not enough learning) or exactly replicated the training data (over-fitting). In this case, we are working with a much bigger data set, which should provide enough data to avoid over-fitting, but will also take more time to train. To improve your model, you can experiment with tuning the following hyper-parameters:\n",
    "\n",
    "- Use more than one recurrent layer and/or add more memory units (hidden neurons) to each layer. This will allow you to learn more complex structures in the data.\n",
    "- Use sequences longer than 100 characters, which will allow you to learn from patterns further back in time.\n",
    "- Change the way the sequences are generated. For example you could try to break up the text into real sentances using the periods, and then either cut or pad each sentance to make it 100 characters long.\n",
    "- Increase the number of training epochs, which will give the model more time to learn. Monitor the validation loss at each epoch to make sure the model is still improving at each epoch and is not overfitting the training data.\n",
    "- Add more dropout to the recurrent layers to minimize over-fitting.\n",
    "- Tune the batch size - try a batch size of 1 as a (very slow) baseline and larger sizes from there.\n",
    "- Experiment with scale factors (temperature) when interpreting the prediction probabilities.\n",
    "\n",
    "If you get an error such as `alloc error` or `out of memory error` during training it means that  your computer does not have enough RAM memory to store the model parameters or the batch of training data needed during a training step. If you run into this issue, try reducing the complexity of your model (both number and depth of layers) or the mini-batch size.\n",
    "\n",
    "The last three code blocks will use your trained model to generate a sequence of text based on a predefined seed. Do not change any of the code, but run it before submitting your assignment. Your work will be evaluated based on the quality of the generated text. A good result should be legible with decent grammar and spelling (this indicates a high level of learning), but the exact text should not be found anywhere in the actual text (this indicates over-fitting).\n",
    "\n",
    "Let's start by importing the libraries we will be using, and importing the full text from Alice in Wonderland:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from time import gmtime, strftime\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of text: 141266\n",
      "text preview: alices adventures in wonderland\n",
      "\n",
      "lewis carroll\n",
      "\n",
      "the millennium fulcrum edition 3.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "chapter i. down the rabbit-hole\n",
      "\n",
      "alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of having nothing to do: once or twice she had peeped into the\n",
      "book her sister was reading, but it had no pictures or conversations in\n",
      "it, and what is the use of a book, thought alice without pictures or\n",
      "conversations?\n",
      "\n",
      "so she was considering in her own mind as well as she could, for the\n",
      "hot day mad\n"
     ]
    }
   ],
   "source": [
    "filename = \"data/wonderland.txt\"\n",
    "raw_text = open(filename).read()\n",
    "\n",
    "raw_text = re.sub('[^\\nA-Za-z0-9 ,.:;?!-]+', '', raw_text)\n",
    "raw_text = raw_text.lower()\n",
    "\n",
    "n_chars = len(raw_text)\n",
    "print \"length of text:\", n_chars\n",
    "print \"text preview:\", raw_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique characters found: 37\n",
      "a - maps to -> 11\n",
      "25 - maps to -> o\n"
     ]
    }
   ],
   "source": [
    "# write your code here\n",
    "# extract all unique characters in the text\n",
    "#The method list() takes sequence types and converts them to lists. This is used to convert a given tuple into list\n",
    "chars = sorted(list(set(raw_text)))\n",
    "n_vocab = len(chars)\n",
    "print \"number of unique characters found:\", n_vocab\n",
    "\n",
    "# create mapping of characters to integers and back\n",
    "#create dictionary of characters and numbers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# test our mapping\n",
    "print 'a', \"- maps to ->\", char_to_int[\"a\"]\n",
    "print 25, \"- maps to ->\", int_to_char[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sequences:  141116\n"
     ]
    }
   ],
   "source": [
    "#set longer sequence length to let the model trace back more and thus get higher accuracy\n",
    "seq_length = 150\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    inputs.append(raw_text[i:i + seq_length])\n",
    "    outputs.append(raw_text[i + seq_length])\n",
    "    \n",
    "n_sequences = len(inputs)\n",
    "print \"Total sequences: \", n_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consultation about this, and after a few minutes it seemed quite natural\n",
      "to alice to find herself talking familiarly with them, as if she had\n",
      "known th --> e\n"
     ]
    }
   ],
   "source": [
    "#shuffle the indecs that are shared by both inputs and outputs \n",
    "#for convenience of spliting them into training and test data\n",
    "indeces = range(len(inputs))\n",
    "random.shuffle(indeces)\n",
    "\n",
    "inputs = [inputs[x] for x in indeces]\n",
    "outputs = [outputs[x] for x in indeces]\n",
    "print inputs[0], \"-->\", outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X dims --> (141116, 150, 37)\n",
      "y dims --> (141116, 37)\n"
     ]
    }
   ],
   "source": [
    "# create two empty numpy array with the proper dimensions\n",
    "X = np.zeros((n_sequences, seq_length, n_vocab), dtype=np.bool)\n",
    "y = np.zeros((n_sequences, n_vocab), dtype=np.bool)\n",
    "\n",
    "# iterate over the data and build up the X and y data sets\n",
    "# by setting the appropriate indices to 1 in each one-hot vector\n",
    "for i, example in enumerate(inputs):\n",
    "    for t, char in enumerate(example):\n",
    "        X[i, t, char_to_int[char]] = 1\n",
    "    y[i, char_to_int[outputs[i]]] = 1\n",
    "    \n",
    "print 'X dims -->', X.shape\n",
    "print 'y dims -->', y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(32, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
    "\n",
    "#add up the dropout probability to minimize the overfitting problem\n",
    "model.add(Dropout(0.30))\n",
    "\n",
    "#add extra recurrent layer to train the model with more complex structures\n",
    "#reducing the hidden neurons in Recurrent layers to decay the model complexity and speed up learning process\n",
    "model.add(LSTM(64))\n",
    "#add up the dropout probability to minimize the overfitting problem\n",
    "model.add(Dropout(0.30))\n",
    "\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do not change this code, but run it before submitting your assignment to generate the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(sentence, sample_length=50, diversity=0.5):\n",
    "    generated = sentence\n",
    "    sys.stdout.write(generated)\n",
    "\n",
    "    for i in range(sample_length):\n",
    "        x = np.zeros((1, X.shape[1], X.shape[2]))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x[0, t, char_to_int[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = int_to_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"-advanced_LSTM.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 30\n",
      "Train on 112892 samples, validate on 28224 samples\n",
      "Epoch 1/1\n",
      "112892/112892 [==============================] - 2337s - loss: 2.6928 - val_loss: 2.3348\n",
      "----- generating with seed: bout among those beds of bright flowers and\n",
      "those cool fountains, but she could not even get her head through the\n",
      "doorway; and even if my head would g\n",
      "bout among those beds of bright flowers and\n",
      "those cool fountains, but she could not even get her head through the\n",
      "doorway; and even if my head would ge beus lor to aqse said the sot at oll she ar int yoar ey the she lhe the wor end got woile wfet the sher tint in\n",
      "dhe sae she ter wece bot ure al at te moal in the the bind the he bary on ser the the gor on ans an, she onn aud an the the white fand in and malt we she peto tat tee sis le to se an\n",
      "en we the ser wues an ans an she se ale an as an lor urpent war alt tar the won ho he toe an sat the she shon for int lhen she ind af the the the int and ind an be ler hute woce whand tor whe the bher th\n",
      "bout among those beds of bright flowers and\n",
      "those cool fountains, but she could not even get her head through the\n",
      "doorway; and even if my head would geo ag the n! mis klin indy hhe;ee shimag\n",
      "os motity ratsrided\n",
      "\n",
      "iy ty sat\n",
      "jrisb ne m-e\n",
      "lofeneid ehhy on\n",
      "?h-id aus, dnten. onrelr,l dlad\n",
      "thhe bacbwed. fas, tok nate\n",
      "d afrce qoet ayy whers, thert\n",
      "vt yhad aeu; tho pen! errhaod w adryett  shas o vhime fam ranse ann\n",
      "ia bond tho midtimfse\n",
      "p mod let ifrter, messd de saangl re thhed blad a fftal orleiod lor woes wered, biis ke kofdhl dviy-;e ghite its toise\n",
      " wacew ancinat\n",
      "wanetlang levenr, any isen agoytii ind hh\n",
      "rit iwht hhe lob\n",
      "hel a loyme mitpak as.\n",
      ", \n",
      "epoch: 2 / 30\n",
      "Train on 112892 samples, validate on 28224 samples\n",
      "Epoch 1/1\n",
      "112892/112892 [==============================] - 1001s - loss: 2.3621 - val_loss: 2.1609\n",
      "----- generating with seed: ean you cant take less, said the hatter: its very easy to take\n",
      "more than nothing.\n",
      "\n",
      "nobody asked your opinion, said alice.\n",
      "\n",
      "whos making personal remark\n",
      "ean you cant take less, said the hatter: its very easy to take\n",
      "more than nothing.\n",
      "\n",
      "nobody asked your opinion, said alice.\n",
      "\n",
      "whos making personal remarke her sere hhite the sitse all the dalg leithe wers ant the cerend the the tit the ot the ins walt the gent at were it o noring win hang and the wach at with the certing the the god the the sous the her at and the ote fous and bot to cin her, the wind the herlige dout lere the ove alid the the wut a cerer the the tat it in the sone the tare foud not meaw as wor the hat the the ther at the mate and the the womk thit the the and the kle the the cort and the wing the nont of the morele at and wout \n",
      "ean you cant take less, said the hatter: its very easy to take\n",
      "more than nothing.\n",
      "\n",
      "nobody asked your opinion, said alice.\n",
      "\n",
      "whos making personal remarkebad won. tole tant andebo, o the a pore at kap\n",
      "toed, ancit  ibetsow; salt in.\n",
      "\n",
      "ote qridty! corlslace denblep sat nfares yeatled herrerif.\n",
      "\n",
      "hit. petu the! dhinr bigbas the mote wak one thonk? largg ond, bonit in\n",
      "bewalt. !ll menhe tam the ;ogoy a biad was\n",
      "eis, bene onetfa,d su? wadlyd notk henll is hakl cilgrisnd co ebes! ace hery fol fen, bargyla  nampyt hor rewlezy,u ab ow dime. ohts, yund cesres, gitufw callad, howttendden the, of cakpsen cbiceltlag. oad: hhine. d toued aky ? sa shul, ta tnded\n",
      "epoch: 3 / 30\n",
      "Train on 112892 samples, validate on 28224 samples\n",
      "Epoch 1/1\n",
      "112892/112892 [==============================] - 4433s - loss: 2.2487 - val_loss: 2.0635\n",
      "----- generating with seed: e white rabbit read:--\n",
      "\n",
      "   they told me you had been to her,\n",
      "    and mentioned me to him:\n",
      "   she gave me a good character,\n",
      "    but said i could not sw\n",
      "e white rabbit read:--\n",
      "\n",
      "   they told me you had been to her,\n",
      "    and mentioned me to him:\n",
      "   she gave me a good character,\n",
      "    but said i could not swe said in betene to aros of an the mat the mare to was the nehen sas hen sithe rot the sous she kery sout the mace sous you the kaed the kad ale the heres at and the toune the sous has, and the the lettter cour? thow and cout in the ca her and and the fore at pound the cune don lose the saad the kand in whan as hor and and and and the kon was the sice the sud wert the roon lite to the more alice nound and the the hat and on she harke soun the cares of leow bout out the cerery the and the wad, th\n",
      "e white rabbit read:--\n",
      "\n",
      "   they told me you had been to her,\n",
      "    and mentioned me to him:\n",
      "   she gave me a good character,\n",
      "    but said i could not swe-hhouge abfsce diades\n",
      "erwergins. shex fuingn.\n",
      "\n",
      "i fep atfem weper gunging misite mnay\n",
      "chome\n",
      "oof of; an, sout. fharss when, af cermter.t the to paceo. chand.:\n",
      "thing.t-asf-and bhimnvo!-\n",
      "thitg massiceite, seir homeng? lice burging in tho nrinls. thes loen lnyporin? hin yryingtatiog? leres!. noys pnesen,!\n",
      "\n",
      "- r wut wuuvace atisger, leo, toneuct ulwitd\n",
      "vall\n",
      "benns\n",
      "onpaod wo?iuded wo shin yatr ank someli\n",
      "a lirjenpn,\n",
      "if in sop ot, -ho pite. an\n",
      "beved he, tithre.; then ceon oumoce-:ls sroive naser, doutise\n",
      "epoch: 4 / 30\n",
      "Train on 112892 samples, validate on 28224 samples\n",
      "Epoch 1/1\n",
      "112892/112892 [==============================] - 2365s - loss: 2.1742 - val_loss: 1.9991\n",
      "----- generating with seed:  the mouse, who seemed to be a person of authority among them,\n",
      "called out, sit down, all of you, and listen to me! ill soon make you\n",
      "dry enough! they \n",
      " the mouse, who seemed to be a person of authority among them,\n",
      "called out, sit down, all of you, and listen to me! ill soon make you\n",
      "dry enough! they sore alice wish the sied the dore time wand vaid the dore part the merten suid she wis a cuate of the same alice say and the lore hoxl seing and and to curite and the mack her, the latter her heand the was the allite of the wore wad the sote on the moude ind as it a dore wort the crepeper wis of on why gaid ill the doand the was so mepere it was the hore tued and and-id a wand the hithen curt at it bey the sas the qaate the kint her coull ald in and the mond tere to dere rishend the sousd all bo\n",
      " the mouse, who seemed to be a person of authority among them,\n",
      "called out, sit down, all of you, and listen to me! ill soon make you\n",
      "dry enough! they wore thy yuiss the yows the ilp,eh\n",
      "sus ith, adiot uyr thas uubed elosryrinc\n",
      "on, riwlgip sor, ardy, iviin.\n",
      "\n",
      "yucclire\n",
      "gounl, yhe duchet off.\n",
      "\n",
      " mitex, soaid tye wisan avick on,et.\n",
      "\n",
      "hersy. ifmome. bance sreeh sayn! indy on.\n",
      "\n",
      "taelm onn nedlocoubef, rrohtome eokt, talelat:, asd,?\n",
      "\n",
      " calbled the raote\n",
      "aroke yie! the i hichef bapme pos yeidtloce\n",
      "yamuwfth.\n",
      "\n",
      "a meigung aid thall\n",
      "semang of? tued. a ashe said she toh inhire amitle buthfnd quethr elsounxy me ssomud loove fout arichery-wlhe !rien pyiply dovid! \n",
      "epoch: 5 / 30\n",
      "Train on 112892 samples, validate on 28224 samples\n",
      "Epoch 1/1\n",
      "112892/112892 [==============================] - 2110s - loss: 2.1230 - val_loss: 1.9506\n",
      "----- generating with seed: had a head could be\n",
      "beheaded, and that you werent to talk nonsense.\n",
      "\n",
      "the queens argument was, that if something wasnt done about it in less\n",
      "than no ti\n",
      "had a head could be\n",
      "beheaded, and that you werent to talk nonsense.\n",
      "\n",
      "the queens argument was, that if something wasnt done about it in less\n",
      "than no tiss whith the courd the not? the wat dound and she this mowed and of the cuger a lows the goon the suster and the ked the sould her the co rore to tho lite bat and the weas the ked and thit and at in whas the wat lo the rat the moute cound the sout it tat the the sack so chere you sure and and it and reang the soud in of wos had the har, the her and the wat the dorteng tard the hard and the dourd wore wo datce it got the wand curhered nos the queend the wert mound the sad the coren of she jutd th\n",
      "had a head could be\n",
      "beheaded, and that you werent to talk nonsense.\n",
      "\n",
      "the queens argument was, that if something wasnt done about it in less\n",
      "than no timk\n",
      "citspite,.\n",
      "\n",
      "naad the cunceacjentfafy bat a ho leapeinny pams, i found, i you jrecn fugrs the soursede whid it see madh. wouder they? serket, bugsen. che, one\n",
      "the rottouf an autigwveis. wutl was jemss hinging in a-dotths!itsty os, in wenn ow that; g pordbatl in she dougippever, to kan thisd that\n",
      "sece so hor moks io dafmatte, tao way afel cash\n",
      "shate anting sfen, sai hid, dofnsk is anlt aver theze?a\n",
      "ou wamic!y she all, necw, qneten-?s\n",
      "abhe tow nos\n",
      "a dy she it may maicy, and\n",
      "tenknotsan to shimy i\n",
      "epoch: 6 / 30\n",
      "Train on 112892 samples, validate on 28224 samples\n",
      "Epoch 1/1\n",
      "112892/112892 [==============================] - 2366s - loss: 2.0785 - val_loss: 1.9109\n",
      "----- generating with seed: l children, and everybody else.\n",
      "\n",
      "leave off that! screamed the queen. you make me giddy. and then,\n",
      "turning to the rose-tree, she went on, what have you\n",
      "l children, and everybody else.\n",
      "\n",
      "leave off that! screamed the queen. you make me giddy. and then,\n",
      "turning to the rose-tree, she went on, what have you the ridter her courd of fen the way to she sand to cer the courd and to hat the was in at the was that sour the mertend a dartle, and a wong the with and and the kad the mister and the king a doon to be on the kere gerther firded the what was it she she got is the courd alice the was the quite ald her the tore the dro had has the has sound the queet of wont the core at the with the lasting the kent it so in all it the sing so had of the gont pord the shen on ind the ming alr the hand sore sat k\n",
      "l children, and everybody else.\n",
      "\n",
      "leave off that! screamed the queen. you make me giddy. and then,\n",
      "turning to the rose-tree, she went on, what have you cow heot turt? the mos. and bightaing mile-ver\n",
      "tox deadd\n",
      "rasco besllly ut i raght of tore hawing, and in ind hen si esozerd weal. hed\n",
      "sircing the du,s whithelk agrting und, add bee ha, she-led ofe she! ou mit id in wertebetf a cralle o, ias, main in shep ther.\n",
      "\n",
      "ferd saed bees, at were har nevol fons the wal be heind ath wsigh was i cualk.\n",
      " wneudile.\n",
      "\n",
      "pilliived! that, dat buk thee sooe; voalidevive.\n",
      "\n",
      "anba deands arly of a, dad idland! tad so ir soe? they baid who oce\n",
      "haree, the wurtibeos\n",
      "yot hea\n",
      "epoch: 7 / 30\n",
      "Train on 112892 samples, validate on 28224 samples\n",
      "Epoch 1/1\n",
      "112892/112892 [==============================] - 1176s - loss: 2.0435 - val_loss: 1.8716\n",
      "----- generating with seed: are to disobey, though she felt sure it would all come\n",
      "wrong, and she went on in a trembling voice:--\n",
      "\n",
      "  i passed by his garden, and marked, with one \n",
      "are to disobey, though she felt sure it would all come\n",
      "wrong, and she went on in a trembling voice:--\n",
      "\n",
      "  i passed by his garden, and marked, with one cat, and nead her hat a lomes the king her sutter as and her her thing she meed lestertert leon the her the the garded of of in the lotken is the hight at of the dott on the mome from gor of in the worter a to sout in that a mast her the sone the melster of her has be the grore ham the sourd of the king of thit whan the cart the forser talk the pinden seing alice on alice of the of the had said the kad, and cunder, and the was wint the round his the\n",
      "got gint it of the saad the dook the wave, and\n",
      "are to disobey, though she felt sure it would all come\n",
      "wrong, and she went on in a trembling voice:--\n",
      "\n",
      "  i passed by his garden, and marked, with one bow,\n",
      "whonerrten lire she\n",
      "bey i liwtere.\n",
      "\n",
      "nes brith.\n",
      "\n",
      ", bull.\n",
      "\n",
      "the liss of apemhed. n ther dost\n",
      "and ad oute. all the eforker. ofle onstly\n",
      "wheuke, i tres to kilt: and; wa miottone thec!; tomh u citen moqklovt!\n",
      "\n",
      "    thatf as opthing fatmed os and seerohokaor.\n",
      "\n",
      "-outs say woke, sawt her hed snoting, salg co ath, hourgon unde, in the mirtle: but: all lleghceualy! wis une chone! bud? shem braveryhluen\n",
      "uvlatter, oute sotosh ad laniiver.a\n",
      "dithsrey taid as b-erines helmrer!.\n",
      "\n",
      "motent sraet martut. te.\n",
      "-\n",
      "uy\n",
      "epoch: 8 / 30\n",
      "Train on 112892 samples, validate on 28224 samples\n",
      "Epoch 1/1\n",
      "112892/112892 [==============================] - 10629s - loss: 2.0125 - val_loss: 1.8427\n",
      "----- generating with seed: ters! shouted the gryphon, with a bound into the air.\n",
      "\n",
      "--as far out to sea as you can--\n",
      "\n",
      "swim after them! screamed the gryphon.\n",
      "\n",
      "turn a somersault in \n",
      "ters! shouted the gryphon, with a bound into the air.\n",
      "\n",
      "--as far out to sea as you can--\n",
      "\n",
      "swim after them! screamed the gryphon.\n",
      "\n",
      "turn a somersault in in a doon the garded the doot in there alice reare the king alice the sister of and she mare souce, and and it for and alice porting alice, and her the goen was she saad alice fertent alice, and the hall how in the gave of found the quaens at the tint had the mook to she wat they for, and her the thould the pinget her very has beto like sourd the hermel and and that the kot and alice the courd the hout the and of the catther the mece, that she was a reand a on a it her was alice the kone it not \n",
      "ters! shouted the gryphon, with a bound into the air.\n",
      "\n",
      "--as far out to sea as you can--\n",
      "\n",
      "swim after them! screamed the gryphon.\n",
      "\n",
      "turn a somersault in of tall and i moxt wall to iting tire abatch hery man.\n",
      "\n",
      "heershyy hed sutner, and? the gypiwien ,nad\n",
      "brituli.\n",
      "\n",
      "whili of listingcuseritl tfrtaed, only      picbe.\n",
      "\n",
      "hotmri they ramaute\n",
      "sayge, and alice. thene alice lvelied seam.\n",
      "\n",
      "thif! aly casts bet thomoqhe hareg, it eor, brepirgow!\n",
      "\n",
      "suroworlopy tu dot: in henn, juyt witt dast was therl\n",
      "cave ,no,- tat to ke ludet po hance were do wonte the betm had:\n",
      "ome sorgit.\n",
      "\n",
      "shen-the ;hed, toney vuat conther, and gore thay\n",
      "the ratserd ao ich and theye fas! a p\n",
      "epoch: 9 / 30\n",
      "Train on 112892 samples, validate on 28224 samples\n",
      "Epoch 1/1\n",
      "112892/112892 [==============================] - 2373s - loss: 1.9844 - val_loss: 1.8184\n",
      "----- generating with seed: sed at having found out a new kind of\n",
      "rule, and vinegar that makes them sour--and camomile that makes\n",
      "them bitter--and--and barley-sugar and such thin\n",
      "sed at having found out a new kind of\n",
      "rule, and vinegar that makes them sour--and camomile that makes\n",
      "them bitter--and--and barley-sugar and such thing it the mose thing the so repand it her in the wat on the gard the said a wont in the was of the dowt the merming on in the sored the gone was the tould to mugt the mides, and a malk the docouse to for excucand off alice of the is beant queen the hid alice the kect the dott serpore a ting a wather deant sime door the was gun poand it a                                                                                                                                                                  \n",
      "sed at having found out a new kind of\n",
      "rule, and vinegar that makes them sour--and camomile that makes\n",
      "them bitter--and--and barley-sugar and such thinl a lige?!\n",
      "\n",
      "efagt fenh thitlt amversne her apdire oats thes looper. ind its fusd. oveowss sreemlting amire chen qleent sald.\n",
      "\n",
      "--arice in all, the plosst bestare if the mrxeednt fazy yom ho paad\n",
      "thages and chalw, toouls cneubplofeior thy agine the yag sils: ooter mlespice dud that, thouged whoued hoeserd, silin, enent, and seice, thes a cowy of thes? ind fapt. and hrowilid, and thy dempenosmoutird loach. ot teet on! amodeefing, of wint, veid ale fittlr-souglt\n",
      "and, anl shimion. thid. aticustes--sa\n",
      "epoch: 10 / 30\n",
      "Train on 112892 samples, validate on 28224 samples\n",
      "Epoch 1/1\n",
      "112892/112892 [==============================] - 1085s - loss: 1.9639 - val_loss: 1.7954\n",
      "----- generating with seed: n inkstand at the lizard\n",
      "as she spoke. the unfortunate little bill had left off writing on his\n",
      "slate with one finger, as he found it made no mark; but\n",
      "n inkstand at the lizard\n",
      "as she spoke. the unfortunate little bill had left off writing on his\n",
      "slate with one finger, as he found it made no mark; but all the mid, she reels of dared the kace of alice\n",
      "on, and of she grow alice so very ither the king it the crome the rister and, for the doon, and the gotter of the cunter the mock that eor the tame ris not one of the pare and the dor the mome\n",
      "thele see was it of the like that cart at the bike she doon the grep ras sread it not moule the mook all the goon at it said the was brear for the mert the roure the gad one on the sither the can! shat her the doure, the haster had sound and wather off in \n",
      "n inkstand at the lizard\n",
      "as she spoke. the unfortunate little bill had left off writing on his\n",
      "slate with one finger, as he found it made no mark; but worll quitse! -natked the, thassed watett to, she mee\n",
      "day! fet on twes sair it. a bit in thell ups\n",
      "etir wold! you, and quii a vowde.\n",
      "\n",
      "yoo no; to dirt so, the shat, so saire! out shurite be. with alice ig.\n",
      " i\n",
      "fwrn-fhezen be oud tlatt!, and alice\n",
      "somat., jut life as in: hhirhs itr with begeo ofube, buading:\n",
      "sreer\n",
      "cant\n",
      "lrsyte hersing\n",
      "ithen, of the siseve?\n",
      "\n",
      "lime anttinbe reeck, saile.\n",
      "\n",
      "thohe this chal thatseis. arder tembs? and\n",
      "ofnerer fermafing were. and, she thiter oot\n",
      "wonus dont, tull thay have \n",
      "epoch: 11 / 30\n",
      "Train on 112892 samples, validate on 28224 samples\n",
      "Epoch 1/1\n",
      "112892/112892 [==============================] - 47518s - loss: 1.9394 - val_loss: 1.7760\n",
      "----- generating with seed: iouser and curiouser! cried alice she was so much surprised, that\n",
      "for the moment she quite forgot how to speak good english; now im\n",
      "opening out like t\n",
      "iouser and curiouser! cried alice she was so much surprised, that\n",
      "for the moment she quite forgot how to speak good english; now im\n",
      "opening out like the dorshen abit and as and the them porsing was in the mand her went a gat the whan the dorat and so be the said the prokned the rome the had the mict at a looken the know the like and the dound and a was quite her out the parter was and said the doon the down the was ave said the dinser a craster the hattan, she down alice frast wout the sone the queen the daster as the bove the bange all the mouse a than, and the moment beging it her alice.\n",
      "\n",
      "the queen alice what the mott care she pack was one \n",
      "iouser and curiouser! cried alice she was so much surprised, that\n",
      "for the moment she quite forgot how to speak good english; now im\n",
      "opening out like the chy sher-gitn, it qletchsadf. \n",
      "\n",
      "\n",
      " htlave abkur, wer mont.\n",
      "\n",
      "yhe guin thiuknter said ang be\n",
      "you,, s wafle aldien, leer ibsrire!s\n",
      "\n",
      "ped. you younputre naght cook: the gott, ard gus to ked has in. vising so, the beanged sarcie.\n",
      " iwshaon halh not\n",
      "pig,o; and i sereeds!\n",
      "dad valinger, said had the marher erbay, miwtao. he dawhends--punco you shemceescred wontly ghen, ald\n",
      "alin.\n",
      "\n",
      "whes to ste me, now withoutarf ceons, gon a farn seling hil., your? in shels manco les ind olrtw eon bukt alicacy than\n",
      "cantan\n",
      "epoch: 12 / 30\n",
      "Train on 112892 samples, validate on 28224 samples\n",
      "Epoch 1/1\n",
      "112892/112892 [==============================] - 2566s - loss: 1.9229 - val_loss: 1.7577\n",
      "----- generating with seed: f, they used to say.\n",
      "\n",
      "so he did, so he did, said the gryphon, sighing in his turn; and both\n",
      "creatures hid their faces in their paws.\n",
      "\n",
      "and how many hou\n",
      "f, they used to say.\n",
      "\n",
      "so he did, so he did, said the gryphon, sighing in his turn; and both\n",
      "creatures hid their faces in their paws.\n",
      "\n",
      "and how many hound a wort alice, the could the dast the peinted out the doom said the dound said the mook all the the wat she grephen to the ganter be a whow wat her to the onger a the caller a said the said the mide the was that her the rages, and her the dace hatsere a wont her all the was a rabpet be to so it of the tank the with and the mook of a to the beang to rearled al alice said the dost the poret with one the fires of a then the hatter were as a croing her to taid and was a beally at the douse, and an\n",
      "f, they used to say.\n",
      "\n",
      "so he did, so he did, said the gryphon, sighing in his turn; and both\n",
      "creatures hid their faces in their paws.\n",
      "\n",
      "and how many hould munce os tyoourh seetepady;\n",
      "thoaght nhy luse, said the fiwty eve simdse, wris-sheres adming\n",
      "norebus. bood dught mithe:\n",
      "i\n",
      "ayrathhow! and,, to seaunt! what liytiater the mowe, see zrpe-ming ondyrafteugat, and reeplijecus?\n",
      "\n",
      "is\n",
      "gey chem, meste-yry pracugh, intlay, ard shipedsell jvlilg, oning you grus reapve his inde, he sas hims, got\n",
      "tikirg on into blowd tho hear.\n",
      "\n",
      "it wat\n",
      "of lirbindyt-fror uvandel. leon mooks\n",
      "efore!\n",
      "iid arger\n",
      "dopnos mo rhtaiy, tcied at sreaser.\n",
      "\n",
      "alled, you laesly and mused ut a\n",
      "\n",
      "epoch: 13 / 30\n",
      "Train on 112892 samples, validate on 28224 samples\n",
      "Epoch 1/1\n",
      "112892/112892 [==============================] - 2161s - loss: 1.9070 - val_loss: 1.7409\n",
      "----- generating with seed: , eager to see the queen.\n",
      "\n",
      "first came ten soldiers carrying clubs; these were all shaped like\n",
      "the three gardeners, oblong and flat, with their hands a\n",
      ", eager to see the queen.\n",
      "\n",
      "first came ten soldiers carrying clubs; these were all shaped like\n",
      "the three gardeners, oblong and flat, with their hands a moulk out it i got at a saice and it so she could mo the quite of all cersered on the queen inting the tould it said a little the dorppon, and were came be day the kad said the dornened a micking the cane to one in hors the door alice over her soor the courd the mound the aaked the mack the was the door ferting so the cace taid the kid so she conlerent the for the was the said the mooken, and the with to grow the cone the was the dortherss have say her the dong the cately was and thing corter a\n",
      ", eager to see the queen.\n",
      "\n",
      "first came ten soldiers carrying clubs; these were all shaped like\n",
      "the three gardeners, oblong and flat, with their hands a luge, a a jike so tome, very reageal.!\n",
      "\n",
      "it! i was pvoe-appillipecpalrex-hatflace.\n",
      "\n",
      "thearnt alice reared, heed gal: yusf yer orf bhouteme\n",
      "o irstilk of a rome onit a veich thine\n",
      "rh whas no igb ago! weand, alice seiss im begip on s the she rhabfa. sha kind dohm to ce geinints.\n",
      "\n",
      "to alkings nosse wanthing shanike. the suresae as all the vnite was packes as the fortheagluty to goorsint\n",
      "yrebked the tiksently fent repewhened fertevirg turt, no memlomowg of and; it preesec,\n",
      "waike? very back an wither bi\n",
      "epoch: 14 / 30\n",
      "Train on 112892 samples, validate on 28224 samples\n",
      "Epoch 1/1\n",
      "112892/112892 [==============================] - 1980s - loss: 1.8914 - val_loss: 1.7266\n",
      "----- generating with seed: cats eat bats, i wonder? and here alice\n",
      "began to get rather sleepy, and went on saying to herself, in a dreamy\n",
      "sort of way, do cats eat bats? do cats \n",
      "cats eat bats, i wonder? and here alice\n",
      "began to get rather sleepy, and went on saying to herself, in a dreamy\n",
      "sort of way, do cats eat bats? do cats the dott a to shat it i must the farge it in a turt the dore her mowe be the tome was of the mouse as alice, she has got be what the cite mans the queen the was gat the dont was to the knot thing the and she mare little tall and a rain the cant hid peringed the sooling and be and hersere, alice.\n",
      "\n",
      "and began to the cant the what it all the that sound the door of pare there thought her one, and the linked to the could and a tither the his bested in a might the house it a clome the had un lett it wa\n",
      "cats eat bats, i wonder? and here alice\n",
      "began to get rather sleepy, and went on saying to herself, in a dreamy\n",
      "sort of way, do cats eat bats? do cats laky tabeed.\n",
      "\n",
      "you! an,\n",
      "apider for bat of bas\n",
      "it part, -stoile, it, sour mouded thore the\n",
      "wastee! wond to youz as the shimfered afchers have jogt apr!-\n",
      "the whatss surle, hadet alice, in inly, boge with bukos,, and\n",
      "a porres:\n",
      "crollipt,\n",
      "woolr the trunn.\n",
      "\n",
      "of thatr-rese moss ubing sime, id, very seepesed am it its trit; alice, batmho, to\n",
      "some the ragonganld.\n",
      "\n",
      "\n",
      " \n",
      "       mrias -    \n",
      " cwuliw of wondle. sermithver, the said, whe tatt leelnensed\n",
      "a cowll?\n",
      "\n",
      "i cas dobr loke it dlowtley exevard,\n",
      "velad guad not\n",
      "epoch: 15 / 30\n",
      "Train on 112892 samples, validate on 28224 samples\n",
      "Epoch 1/1\n",
      "112892/112892 [==============================] - 1735s - loss: 1.8749 - val_loss: 1.7168\n",
      "----- generating with seed: egan running when they liked, and left off when they\n",
      "liked, so that it was not easy to know when the race was over. however,\n",
      "when they had been runnin\n",
      "egan running when they liked, and left off when they\n",
      "liked, so that it was not easy to know when the race was over. however,\n",
      "when they had been running a with the care said the pock to said is a soon non the varge the cours of the fars to see to see door wont her the was the mooked of thing it were her had of the said the say the gester had had a of the dore cinting the turter the what she her hore the dorstered the cattore to her the king a thought the harted the hach the care to dere said the hear the dorlily all it, and she ras one garded of see king tho the tuct of the bad the her beot of the oud like her alice when her a for the grephed \n",
      "egan running when they liked, and left off when they\n",
      "liked, so that it was not easy to know when the race was over. however,\n",
      "when they had been running if?\n",
      "she.\n",
      "\n",
      "runtires\n",
      "you!s to suand teslire\n",
      "foldle enouh that ot a beturet.\n",
      "\n",
      "qhimently\n",
      "sotf hid the agst: sreidm beas the kingbiry.\n",
      "\n",
      "thero, rotxout, os riwll hoidd, with: stend momy bot said fos\n",
      "inseepgeremleg to hiss.\n",
      "\n",
      "the queon.\n",
      "\n",
      "homell verin gow, be,, we tikes no leyfs, yyos! and i she gayes dep, sow ceoming when and buge taer ngrare porcque har you, xech o, she. i\n",
      "camy dolv! as cuod the midse,\n",
      "at chas! of her batde but\n",
      "the he shits, the lorseryy, shoud sas, ere.\n",
      " the game hagues hind. ceaded\n",
      "epoch: 16 / 30\n",
      "Train on 112892 samples, validate on 28224 samples\n",
      "Epoch 1/1\n",
      "112892/112892 [==============================] - 2458s - loss: 1.8640 - val_loss: 1.7005\n",
      "----- generating with seed: as linked\n",
      "into hers began to tremble. alice looked up, and there stood the queen\n",
      "in front of them, with her arms folded, frowning like a thunderstorm.\n",
      "as linked\n",
      "into hers began to tremble. alice looked up, and there stood the queen\n",
      "in front of them, with her arms folded, frowning like a thunderstorm. inding courd alice and the mouse all the read a little wish in she cathing the door the door in a ringer sour the doon to the pisted the mought the hasting of and courded the raster she was said all foor was shous the catered in a pitser on what the tould of the fingented the could in a was said the thought the door tarker of is the foor the cateing the said all she said the would the write said she not the toused the was ale all grow was thes wat the looked an alice withen the gornen of the ca\n",
      "as linked\n",
      "into hers began to tremble. alice looked up, and there stood the queen\n",
      "in front of them, with her arms folded, frowning like a thunderstorm.\n",
      "\n",
      "sheaver itsitis epleand,\n",
      "and mepank:\n",
      "then the mouge put, mouwh blattle surbhwervyryoh ttours eraryvils; said at you vady nfaad in what weor\n",
      "had loush that i mebe thowes way the madely, see looked queed wis. tame\n",
      "unsaly the nouss illen--uy tredking, as of drasst, in triigecn they\n",
      "hidver dosmacizen her dont she\n",
      "sall ablettire.\n",
      "\n",
      "af itlied dhimun eor, ju herd alice sook anhthert at thiunst.-\n",
      "choo:s\n",
      "the\n",
      "cay? winu-uveryrling it\n",
      "was nint, out rather morght. when say.\n",
      "\n",
      "oz theas, won sheneouited fand o\n",
      "epoch: 17 / 30\n",
      "Train on 112892 samples, validate on 28224 samples\n",
      "Epoch 1/1\n",
      " 33152/112892 [=======>......................] - ETA: 1731s - loss: 1.8627"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9da08093c27d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'epoch:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#reducing the batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# get random starting point for seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vagrant/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/vagrant/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1104\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vagrant/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    822\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vagrant/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0mupdated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vagrant/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    708\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 710\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    711\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vagrant/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 908\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vagrant/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 958\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    959\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/vagrant/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vagrant/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    945\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    946\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prediction_length = 500\n",
    "#augment the training process by adding up the epochs of training\n",
    "epochs = 30\n",
    "\n",
    "for iteration in range(epochs):\n",
    "    \n",
    "    print 'epoch:', iteration + 1, '/', epochs\n",
    "    #reducing the batch size\n",
    "    model.fit(X, y, validation_split=0.2, batch_size=128, nb_epoch=1, callbacks=callbacks_list)\n",
    "    \n",
    "    # get random starting point for seed\n",
    "    start_index = random.randint(0, len(raw_text) - seq_length - 1)\n",
    "    # extract seed sequence from raw text\n",
    "    seed = raw_text[start_index: start_index + seq_length]\n",
    "    \n",
    "    print '----- generating with seed:', seed\n",
    "    \n",
    "    for diversity in [0.5, 1.2]:\n",
    "        generate(seed, prediction_length, diversity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
